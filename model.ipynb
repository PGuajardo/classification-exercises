{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65149b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import env\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af60083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic_df = titanic.copy()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d5e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic(df):\n",
    "    '''\n",
    "    take in titanc dataframe, remove all rows where age or embarked is null, \n",
    "    get dummy variables for sex and embark_town, \n",
    "    and drop sex, deck, passenger_id, class, and embark_town. \n",
    "    '''\n",
    "\n",
    "    df = df[(df.age.notna()) & (df.embarked.notna())]\n",
    "    df = df.drop(columns=['deck', 'passenger_id', 'class'])\n",
    "\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], prefix=['sex', 'embark'])\n",
    "\n",
    "    df = pd.concat([df, dummy_df.drop(columns=['sex_male'])], axis=1)\n",
    "\n",
    "    df = df.drop(columns=['sex', 'embark_town', 'embarked']) \n",
    "\n",
    "    df = df.rename(columns={\"sex_female\": \"is_female\"})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f385c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_Cherbourg</th>\n",
       "      <th>embark_Queenstown</th>\n",
       "      <th>embark_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0          0   \n",
       "1         1       1  38.0      1      0  71.2833      0          1   \n",
       "2         1       3  26.0      0      0   7.9250      1          1   \n",
       "3         1       1  35.0      1      0  53.1000      0          1   \n",
       "4         0       3  35.0      0      0   8.0500      1          0   \n",
       "\n",
       "   embark_Cherbourg  embark_Queenstown  embark_Southampton  \n",
       "0                 0                  0                   1  \n",
       "1                 1                  0                   0  \n",
       "2                 0                  0                   1  \n",
       "3                 0                  0                   1  \n",
       "4                 0                  0                   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = prep_titanic(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa22555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes)\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .25*.90= 22.5% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2,  \n",
    "                                            stratify=df[target])\n",
    "    \n",
    "    \n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3d2d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(titanic_df, target = 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c235d5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 11), (171, 11), (143, 11))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d49677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 398 entries, 500 to 100\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   survived            398 non-null    int64  \n",
      " 1   pclass              398 non-null    int64  \n",
      " 2   age                 398 non-null    float64\n",
      " 3   sibsp               398 non-null    int64  \n",
      " 4   parch               398 non-null    int64  \n",
      " 5   fare                398 non-null    float64\n",
      " 6   alone               398 non-null    int64  \n",
      " 7   is_female           398 non-null    uint8  \n",
      " 8   embark_Cherbourg    398 non-null    uint8  \n",
      " 9   embark_Queenstown   398 non-null    uint8  \n",
      " 10  embark_Southampton  398 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), uint8(4)\n",
      "memory usage: 26.4 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03b468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline1'] = 0\n",
    "\n",
    "validate['baseline1'] = 0\n",
    "\n",
    "test['baseline1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a974320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    237\n",
       "1    161\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45ea5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b93c5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 59.55%\n",
      "baseline accuracy: 59.65%\n",
      "baseline accuracy: 59.44%\n"
     ]
    }
   ],
   "source": [
    "baseline_accuracy = (train.survived == train.baseline1).mean()\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "\n",
    "baseline_accuracy = (validate.survived == validate.baseline1).mean()\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "\n",
    "baseline_accuracy = (test.survived == test.baseline1).mean()\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37812de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab71b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived', 'baseline1'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'baseline1'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'baseline1'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a020186",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0147d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5a57ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b6e1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "562f50d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "614cf539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_decision_tree.pdf'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = export_graphviz(clf2, feature_names= X_train.columns, rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "672e3207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred2[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bb7ecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27716486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.6       ],\n",
       "       [0.90909091, 0.09090909],\n",
       "       [0.90909091, 0.09090909],\n",
       "       [0.42553191, 0.57446809]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5c0b171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72727273, 0.27272727],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.9       , 0.1       ],\n",
       "       [0.53333333, 0.46666667]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba2 = clf2.predict_proba(X_train)\n",
    "y_pred_proba2[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd005fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c119f5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ac9ca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[193,  44],\n",
       "       [ 21, 140]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04b79769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Descision Tree Model\n",
      "-------------------------------\n",
      "True Positive Rate:  0.9\n",
      "False Positive Rate:  0.24\n",
      "True Negative Rate:  0.76\n",
      "False Negative Rate:  0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"First Descision Tree Model\")\n",
    "print(\"-------------------------------\")\n",
    "#TP/TP+FN\n",
    "print(\"True Positive Rate: \", round((193/ (193+21)), 2))\n",
    "\n",
    "#FP / FP+TN\n",
    "print(\"False Positive Rate: \", round((44 / (44 + 140)), 2))\n",
    "\n",
    "#TN / TN+FP\n",
    "print(\"True Negative Rate: \", round((140 / (140+44)), 2))\n",
    "\n",
    "#FN / FN + TP\n",
    "print(\"False Negative Rate: \", round((21 / (21+193)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "272bb887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236,   1],\n",
       "       [ 25, 136]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a5307de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Descision Tree Model\n",
      "-------------------------------\n",
      "True Positive Rate:  0.9\n",
      "False Positive Rate:  0.01\n",
      "True Negative Rate:  0.99\n",
      "False Negative Rate:  0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Second Descision Tree Model\")\n",
    "print(\"-------------------------------\")\n",
    "#TP/TP+FN\n",
    "print(\"True Positive Rate: \", round((236/ (236+25)), 2))\n",
    "\n",
    "#FP / FP+TN\n",
    "print(\"False Positive Rate: \", round((1 / (1 + 136)), 2))\n",
    "\n",
    "#TN / TN+FP\n",
    "print(\"True Negative Rate: \", round((136/ (136+1)), 2))\n",
    "\n",
    "#FN / FN + TP\n",
    "print(\"False Negative Rate: \", round((25/ (25+236)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e34b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    237\n",
       "1    161\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13ebdf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  193   44\n",
       "1   21  140"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28bb9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual on the left, predicted on the top\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  236    1\n",
       "1   25  136"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "print('Actual on the left, predicted on the top')\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred2), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f245df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.86       237\n",
      "           1       0.76      0.87      0.81       161\n",
      "\n",
      "    accuracy                           0.84       398\n",
      "   macro avg       0.83      0.84      0.83       398\n",
      "weighted avg       0.84      0.84      0.84       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a28a08df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       237\n",
      "           1       0.99      0.84      0.91       161\n",
      "\n",
      "    accuracy                           0.93       398\n",
      "   macro avg       0.95      0.92      0.93       398\n",
      "weighted avg       0.94      0.93      0.93       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aa930",
   "metadata": {},
   "source": [
    "# Evaluate Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e1b45dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f20c7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc5a5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80       102\n",
      "           1       0.70      0.74      0.72        69\n",
      "\n",
      "    accuracy                           0.77       171\n",
      "   macro avg       0.76      0.76      0.76       171\n",
      "weighted avg       0.77      0.77      0.77       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf7c1530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       102\n",
      "           1       0.83      0.72      0.78        69\n",
      "\n",
      "    accuracy                           0.83       171\n",
      "   macro avg       0.83      0.81      0.82       171\n",
      "weighted avg       0.83      0.83      0.83       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2f5540",
   "metadata": {},
   "source": [
    "# Exercises: random forest\n",
    "Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2ba7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = RandomForestClassifier(max_depth=10, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17aef67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e781c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12189297 0.23254398 0.04112155 0.04400997 0.24650336 0.01920298\n",
      " 0.25749233 0.01890116 0.00380245 0.01452924]\n"
     ]
    }
   ],
   "source": [
    "print(clf3.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c35c07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf3.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9ce5e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19669048, 0.80330952],\n",
       "       [0.33332291, 0.66667709],\n",
       "       [0.90635688, 0.09364312],\n",
       "       [0.61694606, 0.38305394],\n",
       "       [0.4179016 , 0.5820984 ],\n",
       "       [0.97343187, 0.02656813],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.06      , 0.94      ],\n",
       "       [0.1637336 , 0.8362664 ],\n",
       "       [0.97343187, 0.02656813],\n",
       "       [0.7810303 , 0.2189697 ],\n",
       "       [0.768     , 0.232     ],\n",
       "       [0.05632909, 0.94367091],\n",
       "       [0.97883117, 0.02116883],\n",
       "       [0.18916667, 0.81083333],\n",
       "       [0.03222222, 0.96777778],\n",
       "       [0.075     , 0.925     ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95105626, 0.04894374],\n",
       "       [0.69160408, 0.30839592],\n",
       "       [0.046     , 0.954     ],\n",
       "       [0.12006952, 0.87993048],\n",
       "       [0.25791721, 0.74208279],\n",
       "       [0.84955519, 0.15044481],\n",
       "       [0.28771795, 0.71228205],\n",
       "       [0.9449026 , 0.0550974 ],\n",
       "       [0.95476052, 0.04523948],\n",
       "       [0.90876997, 0.09123003],\n",
       "       [0.22007737, 0.77992263],\n",
       "       [0.01567974, 0.98432026],\n",
       "       [0.91441411, 0.08558589],\n",
       "       [0.23928231, 0.76071769],\n",
       "       [0.93794712, 0.06205288],\n",
       "       [0.93117874, 0.06882126],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.91019043, 0.08980957],\n",
       "       [0.95136576, 0.04863424],\n",
       "       [0.95428739, 0.04571261],\n",
       "       [0.11      , 0.89      ],\n",
       "       [0.76366242, 0.23633758],\n",
       "       [0.71313964, 0.28686036],\n",
       "       [0.4027381 , 0.5972619 ],\n",
       "       [0.95056655, 0.04943345],\n",
       "       [0.86025302, 0.13974698],\n",
       "       [0.96537054, 0.03462946],\n",
       "       [0.30253397, 0.69746603],\n",
       "       [0.93494866, 0.06505134],\n",
       "       [0.96928571, 0.03071429],\n",
       "       [0.11076923, 0.88923077],\n",
       "       [0.95574895, 0.04425105],\n",
       "       [0.95766234, 0.04233766],\n",
       "       [0.97360317, 0.02639683],\n",
       "       [0.93406926, 0.06593074],\n",
       "       [0.06      , 0.94      ],\n",
       "       [0.68644678, 0.31355322],\n",
       "       [0.89535543, 0.10464457],\n",
       "       [0.04767647, 0.95232353],\n",
       "       [0.11175758, 0.88824242],\n",
       "       [0.94828991, 0.05171009],\n",
       "       [0.72887101, 0.27112899],\n",
       "       [0.92467925, 0.07532075],\n",
       "       [0.0200119 , 0.9799881 ],\n",
       "       [0.96937805, 0.03062195],\n",
       "       [0.98205815, 0.01794185],\n",
       "       [0.32434655, 0.67565345],\n",
       "       [0.80357143, 0.19642857],\n",
       "       [0.95892204, 0.04107796],\n",
       "       [0.95369565, 0.04630435],\n",
       "       [0.75907648, 0.24092352],\n",
       "       [0.78583134, 0.21416866],\n",
       "       [0.73420358, 0.26579642],\n",
       "       [0.08181818, 0.91818182],\n",
       "       [0.98492269, 0.01507731],\n",
       "       [0.17125   , 0.82875   ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.30731629, 0.69268371],\n",
       "       [0.94859075, 0.05140925],\n",
       "       [0.9531903 , 0.0468097 ],\n",
       "       [0.01166667, 0.98833333],\n",
       "       [0.99851867, 0.00148133],\n",
       "       [0.9299026 , 0.0700974 ],\n",
       "       [0.91451827, 0.08548173],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.10852899, 0.89147101],\n",
       "       [0.95030812, 0.04969188],\n",
       "       [0.60222222, 0.39777778],\n",
       "       [0.0282772 , 0.9717228 ],\n",
       "       [0.968     , 0.032     ],\n",
       "       [0.99823295, 0.00176705],\n",
       "       [0.72945887, 0.27054113],\n",
       "       [0.92166648, 0.07833352],\n",
       "       [0.21521212, 0.78478788],\n",
       "       [0.16369048, 0.83630952],\n",
       "       [0.88513889, 0.11486111],\n",
       "       [0.47577102, 0.52422898],\n",
       "       [0.62827899, 0.37172101],\n",
       "       [0.96053474, 0.03946526],\n",
       "       [0.94241561, 0.05758439],\n",
       "       [0.91246799, 0.08753201],\n",
       "       [0.03266792, 0.96733208],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.69916909, 0.30083091],\n",
       "       [0.02606536, 0.97393464],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.75106629, 0.24893371],\n",
       "       [0.815087  , 0.184913  ],\n",
       "       [0.96992778, 0.03007222],\n",
       "       [0.07222222, 0.92777778],\n",
       "       [0.141     , 0.859     ],\n",
       "       [0.84778183, 0.15221817],\n",
       "       [0.169     , 0.831     ],\n",
       "       [0.86993741, 0.13006259],\n",
       "       [0.05202899, 0.94797101],\n",
       "       [0.99656738, 0.00343262],\n",
       "       [0.16248864, 0.83751136],\n",
       "       [0.06      , 0.94      ],\n",
       "       [0.01353689, 0.98646311],\n",
       "       [0.90464611, 0.09535389],\n",
       "       [0.21728552, 0.78271448],\n",
       "       [0.96245186, 0.03754814],\n",
       "       [0.90082435, 0.09917565],\n",
       "       [0.94531206, 0.05468794],\n",
       "       [0.91121331, 0.08878669],\n",
       "       [0.74682493, 0.25317507],\n",
       "       [0.98723404, 0.01276596],\n",
       "       [0.88774459, 0.11225541],\n",
       "       [0.743     , 0.257     ],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.9794042 , 0.0205958 ],\n",
       "       [0.90082435, 0.09917565],\n",
       "       [0.88778138, 0.11221862],\n",
       "       [0.96109621, 0.03890379],\n",
       "       [0.95842567, 0.04157433],\n",
       "       [0.46438945, 0.53561055],\n",
       "       [0.97691378, 0.02308622],\n",
       "       [0.94928713, 0.05071287],\n",
       "       [0.96537054, 0.03462946],\n",
       "       [0.57134641, 0.42865359],\n",
       "       [0.00511237, 0.99488763],\n",
       "       [0.95361905, 0.04638095],\n",
       "       [0.79346662, 0.20653338],\n",
       "       [0.96604471, 0.03395529],\n",
       "       [0.44885714, 0.55114286],\n",
       "       [0.15055653, 0.84944347],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.91725213, 0.08274787],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.06923619, 0.93076381],\n",
       "       [0.1822619 , 0.8177381 ],\n",
       "       [0.97883117, 0.02116883],\n",
       "       [0.89534167, 0.10465833],\n",
       "       [0.89      , 0.11      ],\n",
       "       [0.73331494, 0.26668506],\n",
       "       [0.02766667, 0.97233333],\n",
       "       [0.0200119 , 0.9799881 ],\n",
       "       [0.07607718, 0.92392282],\n",
       "       [0.19515152, 0.80484848],\n",
       "       [0.16406335, 0.83593665],\n",
       "       [0.95476052, 0.04523948],\n",
       "       [0.98279412, 0.01720588],\n",
       "       [0.90625892, 0.09374108],\n",
       "       [0.9136617 , 0.0863383 ],\n",
       "       [0.94704056, 0.05295944],\n",
       "       [0.8990091 , 0.1009909 ],\n",
       "       [0.9531903 , 0.0468097 ],\n",
       "       [0.91295403, 0.08704597],\n",
       "       [0.02570028, 0.97429972],\n",
       "       [0.87912321, 0.12087679],\n",
       "       [0.41564286, 0.58435714],\n",
       "       [0.11591873, 0.88408127],\n",
       "       [0.68769845, 0.31230155],\n",
       "       [0.015     , 0.985     ],\n",
       "       [0.11      , 0.89      ],\n",
       "       [0.91492989, 0.08507011],\n",
       "       [0.99318554, 0.00681446],\n",
       "       [0.92850072, 0.07149928],\n",
       "       [0.26383117, 0.73616883],\n",
       "       [0.98550004, 0.01449996],\n",
       "       [0.02222222, 0.97777778],\n",
       "       [0.12208134, 0.87791866],\n",
       "       [0.03253361, 0.96746639],\n",
       "       [0.6045564 , 0.3954436 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98310662, 0.01689338],\n",
       "       [0.82882305, 0.17117695],\n",
       "       [0.00266667, 0.99733333],\n",
       "       [0.72476545, 0.27523455],\n",
       "       [0.90409091, 0.09590909],\n",
       "       [0.05202899, 0.94797101],\n",
       "       [0.91228414, 0.08771586],\n",
       "       [0.85737243, 0.14262757],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7909016 , 0.2090984 ],\n",
       "       [0.95744048, 0.04255952],\n",
       "       [0.03222222, 0.96777778],\n",
       "       [0.12076923, 0.87923077],\n",
       "       [0.45561606, 0.54438394],\n",
       "       [0.07333333, 0.92666667],\n",
       "       [0.99368931, 0.00631069],\n",
       "       [0.50381846, 0.49618154],\n",
       "       [0.66369123, 0.33630877],\n",
       "       [0.93766234, 0.06233766],\n",
       "       [0.91019043, 0.08980957],\n",
       "       [0.65021564, 0.34978436],\n",
       "       [0.03253361, 0.96746639],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.97928571, 0.02071429],\n",
       "       [0.95629149, 0.04370851],\n",
       "       [0.89246799, 0.10753201],\n",
       "       [0.83037369, 0.16962631],\n",
       "       [0.15841467, 0.84158533],\n",
       "       [0.78263397, 0.21736603],\n",
       "       [0.86656926, 0.13343074],\n",
       "       [0.67021974, 0.32978026],\n",
       "       [0.81318112, 0.18681888],\n",
       "       [0.3242151 , 0.6757849 ],\n",
       "       [0.04222222, 0.95777778],\n",
       "       [0.91295403, 0.08704597],\n",
       "       [0.92304762, 0.07695238],\n",
       "       [0.08515152, 0.91484848],\n",
       "       [0.98536712, 0.01463288],\n",
       "       [0.8820261 , 0.1179739 ],\n",
       "       [0.97634386, 0.02365614],\n",
       "       [0.91019043, 0.08980957],\n",
       "       [0.98578575, 0.01421425],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9136617 , 0.0863383 ],\n",
       "       [0.77833333, 0.22166667],\n",
       "       [0.05166667, 0.94833333],\n",
       "       [0.97656738, 0.02343262],\n",
       "       [0.40618488, 0.59381512],\n",
       "       [0.13424485, 0.86575515],\n",
       "       [0.23107922, 0.76892078],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.32944444, 0.67055556],\n",
       "       [0.86441687, 0.13558313],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.92334233, 0.07665767],\n",
       "       [0.27930898, 0.72069102],\n",
       "       [0.94819226, 0.05180774],\n",
       "       [0.45561606, 0.54438394],\n",
       "       [0.95105626, 0.04894374],\n",
       "       [0.6001248 , 0.3998752 ],\n",
       "       [0.92370685, 0.07629315],\n",
       "       [0.71108575, 0.28891425],\n",
       "       [0.30244012, 0.69755988],\n",
       "       [0.94556887, 0.05443113],\n",
       "       [0.99      , 0.01      ],\n",
       "       [0.96854847, 0.03145153],\n",
       "       [0.02152262, 0.97847738],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.95443079, 0.04556921],\n",
       "       [0.        , 1.        ],\n",
       "       [0.92329827, 0.07670173],\n",
       "       [0.75156926, 0.24843074],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.97467925, 0.02532075],\n",
       "       [0.96906926, 0.03093074],\n",
       "       [0.95197633, 0.04802367],\n",
       "       [0.96069837, 0.03930163],\n",
       "       [0.90625892, 0.09374108],\n",
       "       [0.81952515, 0.18047485],\n",
       "       [0.92469729, 0.07530271],\n",
       "       [0.29502381, 0.70497619],\n",
       "       [0.1633278 , 0.8366722 ],\n",
       "       [0.02067974, 0.97932026],\n",
       "       [0.9275012 , 0.0724988 ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.95883117, 0.04116883],\n",
       "       [0.83834441, 0.16165559],\n",
       "       [0.9149517 , 0.0850483 ],\n",
       "       [0.00266667, 0.99733333],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.051     , 0.949     ],\n",
       "       [0.96057692, 0.03942308],\n",
       "       [0.08317647, 0.91682353],\n",
       "       [0.9314771 , 0.0685229 ],\n",
       "       [0.02506536, 0.97493464],\n",
       "       [0.93752682, 0.06247318],\n",
       "       [0.94499308, 0.05500692],\n",
       "       [0.96140064, 0.03859936],\n",
       "       [0.87666667, 0.12333333],\n",
       "       [0.01285714, 0.98714286],\n",
       "       [0.85314286, 0.14685714],\n",
       "       [0.976     , 0.024     ],\n",
       "       [0.91889106, 0.08110894],\n",
       "       [0.72535678, 0.27464322],\n",
       "       [0.86909091, 0.13090909],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.89496906, 0.10503094],\n",
       "       [0.04506536, 0.95493464],\n",
       "       [0.88421641, 0.11578359],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.76234295, 0.23765705],\n",
       "       [0.91574554, 0.08425446],\n",
       "       [0.0916248 , 0.9083752 ],\n",
       "       [0.66119048, 0.33880952],\n",
       "       [0.96304753, 0.03695247],\n",
       "       [0.97556738, 0.02443262],\n",
       "       [0.76045915, 0.23954085],\n",
       "       [0.76538462, 0.23461538],\n",
       "       [0.04204338, 0.95795662],\n",
       "       [0.9981645 , 0.0018355 ],\n",
       "       [0.96583468, 0.03416532],\n",
       "       [0.99467925, 0.00532075],\n",
       "       [0.76672447, 0.23327553],\n",
       "       [0.98883117, 0.01116883],\n",
       "       [0.91836108, 0.08163892],\n",
       "       [0.37856254, 0.62143746],\n",
       "       [0.94174068, 0.05825932],\n",
       "       [0.86179342, 0.13820658],\n",
       "       [0.95428713, 0.04571287],\n",
       "       [0.93804436, 0.06195564],\n",
       "       [0.9400065 , 0.0599935 ],\n",
       "       [0.08619048, 0.91380952],\n",
       "       [0.97291667, 0.02708333],\n",
       "       [0.93374068, 0.06625932],\n",
       "       [0.03      , 0.97      ],\n",
       "       [0.96360317, 0.03639683],\n",
       "       [0.99617717, 0.00382283],\n",
       "       [0.75160943, 0.24839057],\n",
       "       [0.83029762, 0.16970238],\n",
       "       [0.97909091, 0.02090909],\n",
       "       [0.95549784, 0.04450216],\n",
       "       [0.92334233, 0.07665767],\n",
       "       [0.01414228, 0.98585772],\n",
       "       [0.44087369, 0.55912631],\n",
       "       [0.0916248 , 0.9083752 ],\n",
       "       [0.60878011, 0.39121989],\n",
       "       [0.89302298, 0.10697702],\n",
       "       [0.79346662, 0.20653338],\n",
       "       [0.96109621, 0.03890379],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.96137054, 0.03862946],\n",
       "       [0.7621646 , 0.2378354 ],\n",
       "       [0.04893432, 0.95106568],\n",
       "       [0.36017496, 0.63982504],\n",
       "       [0.99617717, 0.00382283],\n",
       "       [0.89113412, 0.10886588],\n",
       "       [0.01353689, 0.98646311],\n",
       "       [0.72887101, 0.27112899],\n",
       "       [0.1337353 , 0.8662647 ],\n",
       "       [0.73146825, 0.26853175],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.3419732 , 0.6580268 ],\n",
       "       [0.14619048, 0.85380952],\n",
       "       [0.94088316, 0.05911684],\n",
       "       [0.085     , 0.915     ],\n",
       "       [0.97481118, 0.02518882],\n",
       "       [0.92      , 0.08      ],\n",
       "       [0.62      , 0.38      ],\n",
       "       [0.20661905, 0.79338095],\n",
       "       [0.2069243 , 0.7930757 ],\n",
       "       [0.05      , 0.95      ],\n",
       "       [0.87010173, 0.12989827],\n",
       "       [0.69916909, 0.30083091],\n",
       "       [0.00222222, 0.99777778],\n",
       "       [0.97469727, 0.02530273],\n",
       "       [0.055     , 0.945     ],\n",
       "       [0.86086409, 0.13913591],\n",
       "       [0.12708134, 0.87291866],\n",
       "       [0.80410714, 0.19589286],\n",
       "       [0.96529106, 0.03470894],\n",
       "       [0.01388889, 0.98611111],\n",
       "       [0.011     , 0.989     ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.05      , 0.95      ],\n",
       "       [0.75105612, 0.24894388],\n",
       "       [0.59079896, 0.40920104],\n",
       "       [0.98291667, 0.01708333],\n",
       "       [0.97730135, 0.02269865],\n",
       "       [0.01285714, 0.98714286],\n",
       "       [0.07298619, 0.92701381],\n",
       "       [0.9134381 , 0.0865619 ],\n",
       "       [0.81462369, 0.18537631],\n",
       "       [0.19494228, 0.80505772],\n",
       "       [0.46194678, 0.53805322],\n",
       "       [0.75438462, 0.24561538],\n",
       "       [0.80383117, 0.19616883],\n",
       "       [0.78821429, 0.21178571],\n",
       "       [0.98279412, 0.01720588],\n",
       "       [0.98556738, 0.01443262],\n",
       "       [0.19060678, 0.80939322],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.10867647, 0.89132353],\n",
       "       [0.42538388, 0.57461612],\n",
       "       [0.81564286, 0.18435714],\n",
       "       [0.91492989, 0.08507011],\n",
       "       [0.99883117, 0.00116883],\n",
       "       [0.90878702, 0.09121298],\n",
       "       [0.11521795, 0.88478205],\n",
       "       [0.02666667, 0.97333333],\n",
       "       [0.72961958, 0.27038042],\n",
       "       [0.94697633, 0.05302367],\n",
       "       [0.83045403, 0.16954597],\n",
       "       [0.94990607, 0.05009393],\n",
       "       [0.96659444, 0.03340556],\n",
       "       [0.12591051, 0.87408949]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = clf3.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4089c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(clf3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3cba7080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[236   1]\n",
      " [ 10 151]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2786eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "-------------------------------\n",
      "True Positive Rate:  0.96\n",
      "False Positive Rate:  0.01\n",
      "True Negative Rate:  0.99\n",
      "False Negative Rate:  0.04\n"
     ]
    }
   ],
   "source": [
    "TP = 236\n",
    "FP = 1\n",
    "FN = 10\n",
    "TN = 151\n",
    "\n",
    "print(\"Random Forest Model\")\n",
    "print(\"-------------------------------\")\n",
    "#TP/TP+FN\n",
    "print(\"True Positive Rate: \", round((TP/ (TP+FN)), 2))\n",
    "\n",
    "#FP / FP+TN\n",
    "print(\"False Positive Rate: \", round((FP / (FP + TN)), 2))\n",
    "\n",
    "#TN / TN+FP\n",
    "print(\"True Negative Rate: \", round((TN/ (TN+FP)), 2))\n",
    "\n",
    "#FN / FN + TP\n",
    "print(\"False Negative Rate: \", round((FN/ (FN+TP)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7a1e249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       237\n",
      "           1       0.99      0.94      0.96       161\n",
      "\n",
      "    accuracy                           0.97       398\n",
      "   macro avg       0.98      0.97      0.97       398\n",
      "weighted avg       0.97      0.97      0.97       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1840f",
   "metadata": {},
   "source": [
    "### Chaning max_depth and min_samples_leaf parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fded2f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[225  12]\n",
      " [ 37 124]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       237\n",
      "           1       0.91      0.77      0.84       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.89      0.86      0.87       398\n",
      "weighted avg       0.88      0.88      0.87       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier(max_depth=5, min_samples_leaf=3)\n",
    "clf4 = clf4.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf4.predict(X_train)\n",
    "#y_pred\n",
    "y_pred_proba2 = clf4.predict_proba(X_train)\n",
    "#y_pred_proba2\n",
    "\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(clf4.score(X_train, y_train)))\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"---------------------------------------------------------\\n\")\n",
    "print(confusion_matrix(y_train, y_pred2))\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"---------------------------------------------------------\\n\")\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1676758e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "-------------------------------\n",
      "True Positive Rate:  0.86\n",
      "False Positive Rate:  0.09\n",
      "True Negative Rate:  0.91\n",
      "False Negative Rate:  0.14\n"
     ]
    }
   ],
   "source": [
    "TP = 225\n",
    "FP = 12\n",
    "FN = 37\n",
    "TN = 124\n",
    "\n",
    "print(\"Random Forest Model\")\n",
    "print(\"-------------------------------\")\n",
    "#TP/TP+FN\n",
    "print(\"True Positive Rate: \", round((TP/ (TP+FN)), 2))\n",
    "\n",
    "#FP / FP+TN\n",
    "print(\"False Positive Rate: \", round((FP / (FP + TN)), 2))\n",
    "\n",
    "#TN / TN+FP\n",
    "print(\"True Negative Rate: \", round((TN/ (TN+FP)), 2))\n",
    "\n",
    "#FN / FN + TP\n",
    "print(\"False Negative Rate: \", round((FN/ (FN+TP)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46988fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf4 = RandomForestClassifier(max_depth=5, min_samples_leaf=3)\n",
    "clf4 = clf4.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf4.predict(X_train)\n",
    "#y_pred\n",
    "y_pred_proba2 = clf4.predict_proba(X_train)\n",
    "#y_pred_proba2\n",
    "\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(clf4.score(X_train, y_train)))\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"---------------------------------------------------------\\n\")\n",
    "print(confusion_matrix(y_train, y_pred2))\n",
    "\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(\"---------------------------------------------------------\\n\")\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eac4362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10, 0, -1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05fc4662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.90\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[222  15]\n",
      " [ 26 135]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       237\n",
      "           1       0.90      0.84      0.87       161\n",
      "\n",
      "    accuracy                           0.90       398\n",
      "   macro avg       0.90      0.89      0.89       398\n",
      "weighted avg       0.90      0.90      0.90       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.90\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[224  13]\n",
      " [ 27 134]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       237\n",
      "           1       0.91      0.83      0.87       161\n",
      "\n",
      "    accuracy                           0.90       398\n",
      "   macro avg       0.90      0.89      0.89       398\n",
      "weighted avg       0.90      0.90      0.90       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[223  14]\n",
      " [ 34 127]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       237\n",
      "           1       0.90      0.79      0.84       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.88      0.86      0.87       398\n",
      "weighted avg       0.88      0.88      0.88       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[221  16]\n",
      " [ 43 118]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       237\n",
      "           1       0.88      0.73      0.80       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.86      0.83      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.84\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[214  23]\n",
      " [ 39 122]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       237\n",
      "           1       0.84      0.76      0.80       161\n",
      "\n",
      "    accuracy                           0.84       398\n",
      "   macro avg       0.84      0.83      0.84       398\n",
      "weighted avg       0.84      0.84      0.84       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.80\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[211  26]\n",
      " [ 55 106]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       237\n",
      "           1       0.80      0.66      0.72       161\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.80      0.77      0.78       398\n",
      "weighted avg       0.80      0.80      0.79       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.89\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 27 134]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       237\n",
      "           1       0.89      0.83      0.86       161\n",
      "\n",
      "    accuracy                           0.89       398\n",
      "   macro avg       0.89      0.88      0.88       398\n",
      "weighted avg       0.89      0.89      0.89       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.89\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[223  14]\n",
      " [ 28 133]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       237\n",
      "           1       0.90      0.83      0.86       161\n",
      "\n",
      "    accuracy                           0.89       398\n",
      "   macro avg       0.90      0.88      0.89       398\n",
      "weighted avg       0.90      0.89      0.89       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[222  15]\n",
      " [ 37 124]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       237\n",
      "           1       0.89      0.77      0.83       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.85      0.86       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[215  22]\n",
      " [ 37 124]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       237\n",
      "           1       0.85      0.77      0.81       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.85      0.84      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.84\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 44 117]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88       237\n",
      "           1       0.87      0.73      0.79       161\n",
      "\n",
      "    accuracy                           0.84       398\n",
      "   macro avg       0.85      0.83      0.83       398\n",
      "weighted avg       0.85      0.84      0.84       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.80\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[211  26]\n",
      " [ 53 108]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       237\n",
      "           1       0.81      0.67      0.73       161\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.80      0.78      0.79       398\n",
      "weighted avg       0.80      0.80      0.80       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 29 132]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       237\n",
      "           1       0.88      0.82      0.85       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.88      0.87      0.88       398\n",
      "weighted avg       0.88      0.88      0.88       398\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 30 131]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       237\n",
      "           1       0.87      0.81      0.84       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.88      0.87      0.87       398\n",
      "weighted avg       0.88      0.88      0.88       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[221  16]\n",
      " [ 34 127]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       237\n",
      "           1       0.89      0.79      0.84       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.88      0.86      0.87       398\n",
      "weighted avg       0.88      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 41 120]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       237\n",
      "           1       0.88      0.75      0.81       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.86      0.84      0.84       398\n",
      "weighted avg       0.86      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.83\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[216  21]\n",
      " [ 45 116]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       237\n",
      "           1       0.85      0.72      0.78       161\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.84      0.82      0.82       398\n",
      "weighted avg       0.84      0.83      0.83       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.81\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 58 103]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       237\n",
      "           1       0.84      0.64      0.73       161\n",
      "\n",
      "    accuracy                           0.81       398\n",
      "   macro avg       0.82      0.78      0.79       398\n",
      "weighted avg       0.81      0.81      0.80       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[221  16]\n",
      " [ 31 130]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       237\n",
      "           1       0.89      0.81      0.85       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.88      0.87      0.88       398\n",
      "weighted avg       0.88      0.88      0.88       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 32 129]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90       237\n",
      "           1       0.88      0.80      0.84       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.88      0.86      0.87       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 34 127]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       237\n",
      "           1       0.88      0.79      0.83       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.86      0.86       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 31 130]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       237\n",
      "           1       0.87      0.81      0.84       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.86      0.87       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.82\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[215  22]\n",
      " [ 51 110]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.85       237\n",
      "           1       0.83      0.68      0.75       161\n",
      "\n",
      "    accuracy                           0.82       398\n",
      "   macro avg       0.82      0.80      0.80       398\n",
      "weighted avg       0.82      0.82      0.81       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.78\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[206  31]\n",
      " [ 55 106]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       237\n",
      "           1       0.77      0.66      0.71       161\n",
      "\n",
      "    accuracy                           0.78       398\n",
      "   macro avg       0.78      0.76      0.77       398\n",
      "weighted avg       0.78      0.78      0.78       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.88\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 29 132]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       237\n",
      "           1       0.87      0.82      0.85       161\n",
      "\n",
      "    accuracy                           0.88       398\n",
      "   macro avg       0.88      0.87      0.87       398\n",
      "weighted avg       0.88      0.88      0.88       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[213  24]\n",
      " [ 28 133]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       237\n",
      "           1       0.85      0.83      0.84       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.86      0.86       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.86\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 39 122]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       237\n",
      "           1       0.88      0.76      0.81       161\n",
      "\n",
      "    accuracy                           0.86       398\n",
      "   macro avg       0.86      0.84      0.85       398\n",
      "weighted avg       0.86      0.86      0.86       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 43 118]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       237\n",
      "           1       0.87      0.73      0.80       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.86      0.83      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.83\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 51 110]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       237\n",
      "           1       0.86      0.68      0.76       161\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.84      0.80      0.81       398\n",
      "weighted avg       0.83      0.83      0.82       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.79\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[206  31]\n",
      " [ 53 108]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       237\n",
      "           1       0.78      0.67      0.72       161\n",
      "\n",
      "    accuracy                           0.79       398\n",
      "   macro avg       0.79      0.77      0.78       398\n",
      "weighted avg       0.79      0.79      0.79       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 34 127]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       237\n",
      "           1       0.87      0.79      0.83       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.85      0.86       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.87\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 34 127]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       237\n",
      "           1       0.87      0.79      0.83       161\n",
      "\n",
      "    accuracy                           0.87       398\n",
      "   macro avg       0.87      0.85      0.86       398\n",
      "weighted avg       0.87      0.87      0.87       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.86\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 38 123]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       237\n",
      "           1       0.87      0.76      0.81       161\n",
      "\n",
      "    accuracy                           0.86       398\n",
      "   macro avg       0.86      0.84      0.85       398\n",
      "weighted avg       0.86      0.86      0.86       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.83\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 50 111]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       237\n",
      "           1       0.87      0.69      0.77       161\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.84      0.81      0.82       398\n",
      "weighted avg       0.84      0.83      0.83       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.83\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[208  29]\n",
      " [ 40 121]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       237\n",
      "           1       0.81      0.75      0.78       161\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.82      0.81      0.82       398\n",
      "weighted avg       0.83      0.83      0.83       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.80\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 62  99]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       237\n",
      "           1       0.85      0.61      0.71       161\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.81      0.77      0.78       398\n",
      "weighted avg       0.81      0.80      0.79       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[218  19]\n",
      " [ 40 121]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       237\n",
      "           1       0.86      0.75      0.80       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.85      0.84      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[214  23]\n",
      " [ 36 125]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       237\n",
      "           1       0.84      0.78      0.81       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.85      0.84      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.85\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[219  18]\n",
      " [ 42 119]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       237\n",
      "           1       0.87      0.74      0.80       161\n",
      "\n",
      "    accuracy                           0.85       398\n",
      "   macro avg       0.85      0.83      0.84       398\n",
      "weighted avg       0.85      0.85      0.85       398\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.83\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[216  21]\n",
      " [ 45 116]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       237\n",
      "           1       0.85      0.72      0.78       161\n",
      "\n",
      "    accuracy                           0.83       398\n",
      "   macro avg       0.84      0.82      0.82       398\n",
      "weighted avg       0.84      0.83      0.83       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.82\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[220  17]\n",
      " [ 53 108]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86       237\n",
      "           1       0.86      0.67      0.76       161\n",
      "\n",
      "    accuracy                           0.82       398\n",
      "   macro avg       0.83      0.80      0.81       398\n",
      "weighted avg       0.83      0.82      0.82       398\n",
      "\n",
      "Accuracy of random forest classifier on training set: 0.80\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "[[222  15]\n",
      " [ 63  98]]\n",
      "---------------------------------------------------------\n",
      "---------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85       237\n",
      "           1       0.87      0.61      0.72       161\n",
      "\n",
      "    accuracy                           0.80       398\n",
      "   macro avg       0.82      0.77      0.78       398\n",
      "weighted avg       0.81      0.80      0.80       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    for n in range(7, 1, -1):\n",
    "        clf4 = RandomForestClassifier(max_depth=n, min_samples_leaf=i)\n",
    "        clf4 = clf4.fit(X_train, y_train)\n",
    "\n",
    "        y_pred2 = clf4.predict(X_train)\n",
    "        #y_pred\n",
    "        y_pred_proba2 = clf4.predict_proba(X_train)\n",
    "        #y_pred_proba2\n",
    "\n",
    "        print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "         .format(clf4.score(X_train, y_train)))\n",
    "\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"---------------------------------------------------------\\n\")\n",
    "        print(confusion_matrix(y_train, y_pred2))\n",
    "\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"---------------------------------------------------------\\n\")\n",
    "        print(classification_report(y_train, y_pred2))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "181935cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3868dc5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.182932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922111</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.103397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.904523</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.074113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.073246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.055658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.829146</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.051368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.826633</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.054703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.786432</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>-0.008889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.016927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "0          19                1        0.989950           0.807018    0.182932\n",
       "1          18                2        0.922111           0.818713    0.103397\n",
       "2          17                3        0.904523           0.830409    0.074113\n",
       "3          16                4        0.891960           0.818713    0.073246\n",
       "4          15                5        0.874372           0.818713    0.055658\n",
       "..        ...              ...             ...                ...         ...\n",
       "14          5               15        0.829146           0.777778    0.051368\n",
       "15          4               16        0.826633           0.771930    0.054703\n",
       "16          3               17        0.814070           0.771930    0.042141\n",
       "17          2               18        0.786432           0.795322   -0.008889\n",
       "18          1               19        0.753769           0.736842    0.016927\n",
       "\n",
       "[19 rows x 5 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "number_depths = 20\n",
    "\n",
    "for i in range(1,number_depths):\n",
    "    \n",
    "    \n",
    "    depth = number_depths - i\n",
    "    \n",
    "    clf4 = RandomForestClassifier(max_depth = depth, min_samples_leaf = i)\n",
    "    clf4 = clf4.fit(X_train, y_train)\n",
    "\n",
    "    y_pred2 = clf4.predict(X_train)\n",
    "    #y_pred\n",
    "    y_pred_proba2 = clf4.predict_proba(X_train)\n",
    "    #y_pred_proba2\n",
    "\n",
    "    in_sample_accuracy = clf4.score(X_train, y_train)\n",
    "        \n",
    "    out_of_sample_accuracy = clf4.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": depth,\n",
    "        \"min_sample_leaf\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "        \n",
    "    metrics.append(output)\n",
    "    \n",
    "        \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "#df.sort_values(by = ['max_depth', 'min_sample_leaf'], ascending = [False, True])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cdd042c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.063240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.080784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>0.884422</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.065709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.881910</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.063196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.874372</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.049810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.062241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.067266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>0.811558</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.039628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>0.821608</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.043830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0.824121</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.075583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "0          14                3        0.899497           0.836257    0.063240\n",
       "1          14                4        0.899497           0.818713    0.080784\n",
       "2          14                5        0.884422           0.818713    0.065709\n",
       "3          14                6        0.881910           0.818713    0.063196\n",
       "4          14                7        0.874372           0.824561    0.049810\n",
       "..        ...              ...             ...                ...         ...\n",
       "12         14               15        0.834171           0.771930    0.062241\n",
       "13         14               16        0.839196           0.771930    0.067266\n",
       "14         14               17        0.811558           0.771930    0.039628\n",
       "15         14               18        0.821608           0.777778    0.043830\n",
       "16         14               19        0.824121           0.748538    0.075583\n",
       "\n",
       "[17 rows x 5 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by = ['max_depth', 'min_sample_leaf'], ascending = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d380110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sort_values(by = ['max_depth', 'min_sample_leaf'], ascending = [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee84128f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.063240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.899497</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.074936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.064063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.064886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.891960</td>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.055702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.879397</td>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.060684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.861809</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.078183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.834171</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.033001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.811558</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.027932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.894472</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.069911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "0          3               10        0.899497           0.836257    0.063240\n",
       "1          3                9        0.899497           0.824561    0.074936\n",
       "2          3                8        0.894472           0.830409    0.064063\n",
       "3          3                7        0.889447           0.824561    0.064886\n",
       "4          3                6        0.891960           0.836257    0.055702\n",
       "5          3                5        0.879397           0.818713    0.060684\n",
       "6          3                4        0.861809           0.783626    0.078183\n",
       "7          3                3        0.834171           0.801170    0.033001\n",
       "8          3                2        0.811558           0.783626    0.027932\n",
       "9          4               10        0.894472           0.824561    0.069911"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "90b3ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='max_depth'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1.set_index('max_depth')[['train_accuracy', 'validate_accuracy', 'difference']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c056f0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_sample_leaf</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.864322</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.039760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.786432</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>-0.008889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.836683</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.047210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.016927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  min_sample_leaf  train_accuracy  validate_accuracy  difference\n",
       "8          11                9        0.864322           0.824561    0.039760\n",
       "17          2               18        0.786432           0.795322   -0.008889\n",
       "11          8               12        0.836683           0.789474    0.047210\n",
       "16          3               17        0.814070           0.771930    0.042141\n",
       "18          1               19        0.753769           0.736842    0.016927"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.05].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b5744",
   "metadata": {},
   "source": [
    "# KNN Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc7797",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "4. Run through steps 2-4 setting k to 10\n",
    "\n",
    "5. Run through setps 2-4 setting k to 20\n",
    "\n",
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c224a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44ed713b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = acquire.get_titanic_data()\n",
    "titanic_df = titanic.copy()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca5152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic(df):\n",
    "    '''\n",
    "    take in titanc dataframe, remove all rows where age or embarked is null, \n",
    "    get dummy variables for sex and embark_town, \n",
    "    and drop sex, deck, passenger_id, class, and embark_town. \n",
    "    '''\n",
    "\n",
    "    df = df[(df.age.notna()) & (df.embarked.notna())]\n",
    "    df = df.drop(columns=['deck', 'passenger_id', 'class'])\n",
    "\n",
    "    dummy_df = pd.get_dummies(df[['sex', 'embark_town']], prefix=['sex', 'embark'])\n",
    "\n",
    "    df = pd.concat([df, dummy_df.drop(columns=['sex_male'])], axis=1)\n",
    "\n",
    "    df = df.drop(columns=['sex', 'embark_town', 'embarked']) \n",
    "\n",
    "    df = df.rename(columns={\"sex_female\": \"is_female\"})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e786f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = prep_titanic(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7c53b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes)\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .25*.90= 22.5% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2,  \n",
    "                                            stratify=df[target])\n",
    "    \n",
    "    \n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09df792",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(titanic_df, target = 'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6d2878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fe6236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline1'] = 0\n",
    "\n",
    "validate['baseline1'] = 0\n",
    "\n",
    "test['baseline1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1bad7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived', 'baseline1'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'baseline1'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'baseline1'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee7fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e23440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8b37459",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917d868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the accuracy:  0.759\n"
     ]
    }
   ],
   "source": [
    "accuracy = knn.score(X_train, y_train)\n",
    "\n",
    "print(\"This is the accuracy: \", round(accuracy, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47b69a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       237\n",
      "           1       0.70      0.70      0.70       161\n",
      "\n",
      "    accuracy                           0.76       398\n",
      "   macro avg       0.75      0.75      0.75       398\n",
      "weighted avg       0.76      0.76      0.76       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e55034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  48]\n",
      " [ 48 113]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b9ce2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7587939698492462\n"
     ]
    }
   ],
   "source": [
    "print(knn.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d1795da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model\n",
      "-------------------------------\n",
      "True Positive Rate:  0.8\n",
      "False Positive Rate:  0.3\n",
      "True Negative Rate:  0.7\n",
      "False Negative Rate:  0.2\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "Accuracy :  0.76\n",
      "Precision :  0.8\n",
      "Recall :  0.8\n",
      "-------------------------------\n",
      "-------------------------------\n",
      "F1_Score :  0.8\n",
      "Support Positive :  237\n",
      "Support Negative :  161\n"
     ]
    }
   ],
   "source": [
    "TP= 189\n",
    "TN = 113\n",
    "FP = 48\n",
    "FN = 48\n",
    "\n",
    "ALL = TP + TN + FP + FN\n",
    "\n",
    "\n",
    "\n",
    "print(\"KNN Model\")\n",
    "print(\"-------------------------------\")\n",
    "#TP/TP+FN\n",
    "print(\"True Positive Rate: \", round((TP/ (TP+FN)), 2))\n",
    "\n",
    "#FP / FP+TN\n",
    "print(\"False Positive Rate: \", round((FP / (FP + TN)), 2))\n",
    "\n",
    "#TN / TN+FP\n",
    "print(\"True Negative Rate: \", round((TN/ (TN+FP)), 2))\n",
    "\n",
    "#FN / FN + TP\n",
    "print(\"False Negative Rate: \", round((FN/ (FN+TP)), 2))\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "precision = TP/(TP+FP) \n",
    "recall = TP/(TP+FN)\n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "print(\"Accuracy : \", round((accuracy), 2))\n",
    "print(\"Precision : \", round((precision), 2))\n",
    "print(\"Recall : \", round((recall), 2))\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall) \n",
    "support_pos = TP + FN \n",
    "support_neg = FP + TN \n",
    "print(\"-------------------------------\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "print(\"F1_Score : \", round((f1_score), 2))\n",
    "print(\"Support Positive : \", support_pos)\n",
    "print(\"Support Negative : \", support_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf76e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79       237\n",
      "           1       0.71      0.59      0.65       161\n",
      "\n",
      "    accuracy                           0.74       398\n",
      "   macro avg       0.73      0.71      0.72       398\n",
      "weighted avg       0.74      0.74      0.73       398\n",
      "\n",
      "------------------------------------\n",
      "0.7386934673366834\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(10)\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred = knn2.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(\"------------------------------------\")\n",
    "print(knn2.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2cf3788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79       237\n",
      "           1       0.72      0.57      0.63       161\n",
      "\n",
      "    accuracy                           0.74       398\n",
      "   macro avg       0.73      0.71      0.71       398\n",
      "weighted avg       0.73      0.74      0.73       398\n",
      "\n",
      "------------------------------------\n",
      "0.7361809045226131\n"
     ]
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(20)\n",
    "knn3.fit(X_train, y_train)\n",
    "y_pred = knn3.predict(X_train)\n",
    "\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(\"------------------------------------\")\n",
    "print(knn3.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75bb4b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "# loop through different values of k\n",
    "for k in range(1, 21):\n",
    "            \n",
    "    # define the thing\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # fit the thing (remmeber only fit on training data)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # use the thing (calculate accuracy)\n",
    "    train_accuracy = knn.score(X_train, y_train)\n",
    "    validate_accuracy = knn.score(X_validate, y_validate)\n",
    "    \n",
    "    output = {\n",
    "        \"k\": k,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"validate_accuracy\": validate_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "\n",
    "# make a dataframe\n",
    "results = pd.DataFrame(metrics)\n",
    "\n",
    "# plot the data\n",
    "results.set_index('k').plot(figsize = (16,9))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(np.arange(0,21,1))\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477e16d",
   "metadata": {},
   "source": [
    "# Regression Exercises: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2f83577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>None</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class  deck  embark_town  alone  \n",
       "0        S  Third  None  Southampton      0  \n",
       "1        C  First     C    Cherbourg      0  \n",
       "2        S  Third  None  Southampton      1  \n",
       "3        S  First     C  Southampton      0  \n",
       "4        S  Third  None  Southampton      1  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = acquire.get_titanic_data()\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d44d795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  alone  is_female  \\\n",
       "0         0       3  22.0      1      0   7.2500      0          0   \n",
       "1         1       1  38.0      1      0  71.2833      0          1   \n",
       "2         1       3  26.0      0      0   7.9250      1          1   \n",
       "\n",
       "   embark_town_Queenstown  embark_town_Southampton  \n",
       "0                       0                        1  \n",
       "1                       0                        0  \n",
       "2                       0                        1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing ages\n",
    "avg_age = titanic_df.age.mean()\n",
    "titanic_df.age = titanic_df.age.fillna(avg_age)\n",
    "\n",
    "# Encode the gender column\n",
    "titanic_df[\"is_female\"] = (titanic_df.sex == \"female\").astype('int')\n",
    "\n",
    "# Encode the embarked_town\n",
    "# Embark_Town values are Southampton, Cherbourg, and Queenstown\n",
    "dummy_df = pd.get_dummies(titanic_df[['embark_town']], dummy_na=False, drop_first=True)\n",
    "titanic_df = pd.concat([titanic_df, dummy_df], axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "titanic_df = titanic_df.drop(columns=[\"passenger_id\", \"deck\", \"class\", \"embarked\", \"sex\", \"embark_town\"])\n",
    "\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8199211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split_data(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36527bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>is_female</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  is_female  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1          0   \n",
       "165         1       3   9.000000      0      2   20.5250      0          0   \n",
       "50          0       3   7.000000      4      1   39.6875      0          0   \n",
       "259         1       2  50.000000      0      1   26.0000      0          1   \n",
       "306         1       1  29.699118      0      0  110.8833      1          1   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "583                       0                        0  \n",
       "165                       0                        1  \n",
       "50                        0                        1  \n",
       "259                       0                        1  \n",
       "306                       0                        0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb813e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fdb32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = (train.survived == 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7a0affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline is 0.62\n",
      "Logistic Regression using age, pclass, and fare features\n",
      "Accuracy of Logistic Regression classifier on training set:  0.7\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "logit.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit.predict(X_train[features])\n",
    "\n",
    "print(\"Baseline is\", round(baseline_accuracy, 2))\n",
    "print(\"Logistic Regression using age, pclass, and fare features\")\n",
    "print(\"Accuracy of Logistic Regression classifier on training set: \", \n",
    "      round(logit.score(X_train[features], y_train), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e675bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using age, pclass, fare, and gender features\n",
      "Accuracy of Logistic Regression classifier on training set:  0.81\n"
     ]
    }
   ],
   "source": [
    "logit1 = LogisticRegression()\n",
    "\n",
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "logit1.fit(X_train[features], y_train)\n",
    "\n",
    "y_pred = logit1.predict(X_train[features])\n",
    "\n",
    "print(\"Logistic Regression using age, pclass, fare, and gender features\")\n",
    "print(\"Accuracy of Logistic Regression classifier on training set: \", \n",
    "      round(logit1.score(X_train[features], y_train), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74ebb419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all features\n",
      "Accuracy of Logistic Regression classifier on training set:  0.8152610441767069\n"
     ]
    }
   ],
   "source": [
    "logit2 = LogisticRegression()\n",
    "\n",
    "logit2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit2.predict(X_train)\n",
    "\n",
    "print(\"Model trained on all features\")\n",
    "print(\"Accuracy of Logistic Regression classifier on training set: \",\n",
    "    (logit2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7da4e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79       132\n",
      "           1       0.70      0.43      0.53        82\n",
      "\n",
      "    accuracy                           0.71       214\n",
      "   macro avg       0.71      0.66      0.66       214\n",
      "weighted avg       0.71      0.71      0.69       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"age\", \"pclass\", \"fare\"]\n",
    "\n",
    "y_pred = logit.predict(X_validate[features])\n",
    "\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c0b978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       132\n",
      "           1       0.72      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.76      0.76      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"age\", \"pclass\", \"fare\", \"is_female\"]\n",
    "\n",
    "y_pred = logit1.predict(X_validate[features])\n",
    "\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c26e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.82       132\n",
      "           1       0.74      0.65      0.69        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.75      0.76       214\n",
      "weighted avg       0.77      0.78      0.77       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit2.predict(X_validate)\n",
    "\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logit 1 regression has the best results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
